{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Image to 3D Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Material Properties From json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('resized_img_processed_model_mapping.json', 'r') as f:\n",
    "    img_to_mod_map = json.load(f)\n",
    "\n",
    "with open('material_properties.json', 'r') as f:\n",
    "    material_properties = json.load(f)\n",
    "\n",
    "\n",
    "def load_preprocess_img(img_path):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    if img.mode != 'RGB':\n",
    "        # print(f\"Converting grayscale to RGB for: {img_path}\")\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img = ImageOps.colorize(img, black=\"black\", white=\"white\")\n",
    "\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def simplify_mesh(mesh, target_vertices=1024):\n",
    "\n",
    "    open3d_mesh = o3d.geometry.TriangleMesh(\n",
    "        vertices=o3d.utility.Vector3dVector(mesh.vertices),\n",
    "        triangles=o3d.utility.Vector3iVector(mesh.faces)\n",
    "    )\n",
    "\n",
    "    simplified_mesh = open3d_mesh.simplify_quadric_decimation(target_vertices)\n",
    "    simplified_trimesh = trimesh.Trimesh(\n",
    "        vertices=np.asarray(simplified_mesh.vertices),\n",
    "        faces=np.asarray(simplified_mesh.triangles)\n",
    "    )\n",
    "\n",
    "    return simplified_trimesh\n",
    "\n",
    "def upsample_mesh(mesh, target_vertices=1024):\n",
    "    sampled_points, _ = trimesh.sample.sample_surface_even(mesh, target_vertices)\n",
    "    if len(sampled_points) < target_vertices:\n",
    "        padding = np.zeros((target_vertices - len(sampled_points), 3))\n",
    "        return np.vstack([sampled_points, padding])\n",
    "    return sampled_points\n",
    "\n",
    "\n",
    "def load_3d_model(model_path, target_vertices=1024):\n",
    "    mesh = trimesh.load(model_path)\n",
    "\n",
    "    # print(f\"In load_3d: len(mesh.vertices): {len(mesh.vertices)}\")\n",
    "    if len(mesh.vertices) > target_vertices:\n",
    "        simplified_mesh = simplify_mesh(mesh, target_vertices)\n",
    "        # print(f\"Simplify mesh: len(mesh.vertices): {len(mesh.vertices)}\")\n",
    "        return simplified_mesh\n",
    "\n",
    "    elif len(mesh.vertices) < target_vertices:\n",
    "        upsampled_mesh = upsample_mesh(mesh, target_vertices)\n",
    "        # print(f\"Upsample mesh: len(mesh.vertices): {len(mesh.vertices)}\")\n",
    "        return upsampled_mesh\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "\n",
    "def get_material_prop(img_path, img_to_mod_map, material_properties):\n",
    "    # print(img_path)\n",
    "    model_path = img_to_mod_map.get(img_path, None)\n",
    "    print(f\"Processing image: {img_path} with mesh: {model_path}\")\n",
    "\n",
    "    if model_path is None:\n",
    "        raise ValueError(f\"No model found for img: {img_path}\")\n",
    "\n",
    "    material_path = model_path.replace('simple_normal_model.obj', 'model.mtl')\n",
    "    material_path = material_path.replace('../model/', '')\n",
    "    materials = material_properties.get(material_path, None)\n",
    "    if materials is None:\n",
    "        raise ValueError(f\"No materials found for model: {material_path}\")\n",
    "    return materials\n",
    "\n",
    "\n",
    "def normalize_materials(material):\n",
    "    max_shine = 1000\n",
    "\n",
    "    normalized_material = {\n",
    "        'Kd': material.get('diffuse', [1.0, 1.0, 1.0]),\n",
    "        'Ks': material.get('specular', [0.0, 0.0, 0.0]),\n",
    "        'Ns': material.get('shininess', 96.078431) / max_shine,\n",
    "        'Ka': material.get('ambient', [0.0, 0.0, 0.0]),\n",
    "        'd': material.get('transparency', 1.0),\n",
    "        'illumination': material.get('illumination', 2)\n",
    "    }\n",
    "\n",
    "    # Flatten the normalized material into a list for easier processing\n",
    "    flattened_material = (\n",
    "        normalized_material['Kd'] + \n",
    "        normalized_material['Ks'] + \n",
    "        [normalized_material['Ns']] + \n",
    "        normalized_material['Ka'] + \n",
    "        [normalized_material['d'], normalized_material['illumination']]\n",
    "    )\n",
    "    \n",
    "    return flattened_material\n",
    "\n",
    "\n",
    "def preprocess_image_with_material(img_path, img_to_mod_map, material_properties):\n",
    "    img = load_preprocess_img(img_path)\n",
    "\n",
    "    model_path = img_to_mod_map.get(img_path)\n",
    "    mesh = load_3d_model(model_path, target_vertices=1024)\n",
    "\n",
    "    materials = get_material_prop(img_path, img_to_mod_map, material_properties)\n",
    "    normalized_materials = normalize_materials(materials)\n",
    "\n",
    "    return img, mesh, normalized_materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, img_paths, img_to_mod_map, material_properties, batch_size=16, dim=(256, 256, 3), augment=False):\n",
    "        self.img_paths = img_paths\n",
    "        self.img_to_mod_map = img_to_mod_map\n",
    "        self.material_properties = material_properties\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.augment = augment\n",
    "\n",
    "        # Image data augmentation\n",
    "        self.image_datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.img_paths) / self.batch_size))\n",
    "\n",
    "    def pad_or_trunc_mesh(self, mesh, target_vertices=1024):\n",
    "        vertices = np.array(mesh)\n",
    "        # print(f\"Vertices shape before padding: {vertices.shape}\")\n",
    "\n",
    "        if vertices.shape[0] > target_vertices:\n",
    "            return vertices[:target_vertices, :]\n",
    "        elif vertices.shape[0] < target_vertices:\n",
    "            padding = np.zeros((target_vertices - vertices.shape[0], vertices.shape[1]))\n",
    "            return np.vstack([vertices, padding])\n",
    "        else:\n",
    "            return vertices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_img_paths = self.img_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        print(f\"Batch index {index} size: {len(batch_img_paths)}\")\n",
    "\n",
    "        imgs = []\n",
    "        materials = []\n",
    "        meshes = []\n",
    "\n",
    "        for img_path in batch_img_paths:\n",
    "            img = load_preprocess_img(img_path)\n",
    "\n",
    "            # Only squeeze if the image has 4 dimensions\n",
    "            # print(img.shape)\n",
    "            if len(img.shape) == 4 and img.shape[0] == 1:\n",
    "                img = np.squeeze(img, axis=0)  # Remove batch dimension if present\n",
    "\n",
    "            if len(img.shape) == 2: \n",
    "                # print(f\"Converting grayscale to RGB for: {img_path}\")\n",
    "                img = np.stack([img] * 3, axis=-1) \n",
    "\n",
    "            if self.augment:\n",
    "                # print(img.shape)\n",
    "                img = self.image_datagen.random_transform(img)\n",
    "            \n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            imgs.append(img)\n",
    "\n",
    "            material = get_material_prop(img_path, self.img_to_mod_map, self.material_properties)\n",
    "            normalized_material = normalize_materials(material)\n",
    "            materials.append(normalized_material)\n",
    "\n",
    "            model_path = self.img_to_mod_map.get(img_path)\n",
    "            mesh = load_3d_model(model_path)\n",
    "            # print(f\"Mesh type: {type(mesh)} for model: {model_path}\")\n",
    "\n",
    "            if hasattr(mesh, 'vertices'):\n",
    "                vertices_before = len(mesh.vertices)\n",
    "                print(f\"Vertices shape before padding: {vertices_before}\")\n",
    "                padded_mesh = self.pad_or_trunc_mesh(mesh.vertices)\n",
    "                \n",
    "            elif isinstance(mesh, np.ndarray) or isinstance(mesh, trimesh.caching.TrackedArray):\n",
    "                vertices_before = len(mesh)\n",
    "                print(f\"Vertices shape before padding: {vertices_before}\")\n",
    "                padded_mesh = self.pad_or_trunc_mesh(mesh)\n",
    "            else:\n",
    "                print(f\"Warning: No vertices found in model: {model_path}. Skipping.\")\n",
    "                padded_mesh = np.zeros((1024, 3))\n",
    "\n",
    "            # print(f\"Final mesh shape: {padded_mesh.shape}\")\n",
    "            meshes.append(padded_mesh)\n",
    "\n",
    "        imgs = np.vstack(imgs)\n",
    "        materials = np.array(materials, dtype=np.float32)\n",
    "        meshes = np.array(meshes, dtype=np.float32)\n",
    "\n",
    "        imgs_tensor = tf.convert_to_tensor(imgs, dtype=tf.float32)\n",
    "        materials_tensor = tf.convert_to_tensor(materials, dtype=tf.float32)\n",
    "        meshes_tensor = tf.convert_to_tensor(meshes, dtype=tf.float32)\n",
    "\n",
    "        return (imgs_tensor, materials_tensor), meshes_tensor\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.img_paths)\n",
    "        # print(\"Shuffled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "image_input = Input(shape=(256, 256, 3), name='image_input')\n",
    "resnet_base = ResNet50V2(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "\n",
    "x = resnet_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "material_input = Input(shape=(12,), name='material_input')\n",
    "material_dense = Dense(64)(material_input)\n",
    "material_dense = BatchNormalization()(material_dense)\n",
    "material_dense = ReLU()(material_dense)\n",
    "\n",
    "combined = Concatenate()([x, material_dense])\n",
    "\n",
    "z = Dense(256)(combined)\n",
    "z = BatchNormalization()(z)\n",
    "z = ReLU()(z)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = ReLU()(z)\n",
    "\n",
    "output = Dense(1024 * 3, activation='linear', name='output')(z)\n",
    "output_reshaped = Reshape((1024, 3))(output)\n",
    "\n",
    "model = Model(inputs=[image_input, material_input], outputs=output_reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8521 images.\n",
      "Batch index 0 size: 16\n",
      "Processing image: ../resized_images/bed/0229.jpg with mesh: ../model/bed/IKEA_FJELLSE_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1806.jpg with mesh: ../model/chair/IKEA_EKTORP_1/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 728/1024 samples!\n",
      "only got 707/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2528.jpg with mesh: ../model/chair/IKEA_MARIUS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0151.jpg with mesh: ../model/bookcase/IKEA_EXPEDIT_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0340.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 824/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3150.jpg with mesh: ../model/chair/IKEA_REIDAR/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2152.jpg with mesh: ../model/chair/IKEA_JOKKMOKK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0269.jpg with mesh: ../model/bookcase/IKEA_LACK_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 795/1024 samples!\n",
      "only got 684/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/1752.jpg with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0847.jpg with mesh: ../model/table/IKEA_ISALA_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0279.jpg with mesh: ../model/bookcase/IKEA_LACK_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0896.jpg with mesh: ../model/table/IKEA_JOKKMOKK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0797.jpg with mesh: ../model/table/IKEA_INGO_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0159.jpg with mesh: ../model/bed/IKEA_BRIMNES_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0148.jpg with mesh: ../model/table/IKEA_BJORKUDDEN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0128.jpg with mesh: ../model/desk/IKEA_FREDRIK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 792/1024 samples!\n",
      "only got 774/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 0: 0.06857383251190186\n",
      "Batch index 1 size: 16\n",
      "Processing image: ../resized_images/bed/0988.jpg with mesh: ../model/bed/IKEA_VANVIK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/0083.png with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0007.jpg with mesh: ../model/desk/IKEA_BESTA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0909.jpg with mesh: ../model/table/IKEA_JOKKMOKK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 939/1024 samples!\n",
      "only got 706/1024 samples!\n",
      "only got 965/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/sofa/0027.png with mesh: ../model/sofa/IKEA_SATER/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1885.jpg with mesh: ../model/chair/IKEA_FUSION/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1940.jpg with mesh: ../model/sofa/IKEA_VRETA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0128.jpg with mesh: ../model/bookcase/IKEA_EXPEDIT_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0354.jpg with mesh: ../model/bed/IKEA_HEMNES_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 530/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/table/0412.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3655.jpeg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/wardrobe/0112.jpg with mesh: ../model/wardrobe/IKEA_DOMBAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1664.jpg with mesh: ../model/table/IKEA_UTBY_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1564.jpg with mesh: ../model/sofa/IKEA_SKOGABY/model_simple_normal.obj\n",
      "Vertices shape before padding: 1192\n",
      "Processing image: ../resized_images/chair/2271.jpg with mesh: ../model/chair/IKEA_JULES_1/model_0.150864768699_-0.0300872879016_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0708.jpg with mesh: ../model/table/IKEA_INGATORP/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 999/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 1: 0.058192431926727295\n",
      "Batch index 2 size: 16\n",
      "Processing image: ../resized_images/table/0042.png with mesh: ../model/table/IKEA_LACK_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0080.jpg with mesh: ../model/bed/IKEA_BEDDINGE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0249.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0301.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 806/1024 samples!\n",
      "only got 818/1024 samples!\n",
      "only got 706/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0293.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0225.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0205.jpg with mesh: ../model/table/IKEA_BJURSTA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0918.jpg with mesh: ../model/table/IKEA_JOKKMOKK/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 778/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0510.jpg with mesh: ../model/desk/IKEA_MICKE_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3045.jpg with mesh: ../model/chair/IKEA_PREBEN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0108.jpg with mesh: ../model/bed/IKEA_BEDDINGE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0533.jpg with mesh: ../model/desk/IKEA_MICKE_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 704/1024 samples!\n",
      "only got 951/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/bookcase/0124.jpeg with mesh: ../model/bookcase/IKEA_EXPEDIT_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2387.jpg with mesh: ../model/chair/IKEA_KAUSTBY/model_simple_normal.obj\n",
      "Vertices shape before padding: 1029\n",
      "Processing image: ../resized_images/sofa/0819.jpg with mesh: ../model/sofa/IKEA_KIVIK_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0114.jpg with mesh: ../model/table/IKEA_BJORKUDDEN_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 846/1024 samples!\n",
      "only got 776/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 2: 0.05227632820606232\n",
      "Batch index 3 size: 16\n",
      "Processing image: ../resized_images/table/1390.jpg with mesh: ../model/table/IKEA_NORDEN_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2350.jpg with mesh: ../model/chair/IKEA_JULES_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0733.jpg with mesh: ../model/bed/IKEA_LILLESAND/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0945.png with mesh: ../model/bed/IKEA_TROMSO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 898/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/1580.jpg with mesh: ../model/chair/IKEA_BERNHARD/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3572.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3506.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0085.jpg with mesh: ../model/desk/IKEA_BESTA_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 821/1024 samples!\n",
      "only got 862/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/1924.jpg with mesh: ../model/chair/IKEA_INGOLF/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0693.jpg with mesh: ../model/desk/IKEA_GALANT_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3249.jpg with mesh: ../model/chair/IKEA_SNILLE_1/model_0.638510192124_0.0237072979295_simple_normal.obj\n",
      "Vertices shape before padding: 1026\n",
      "Processing image: ../resized_images/chair/1906.jpeg with mesh: ../model/chair/IKEA_HERMAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0047.jpg with mesh: ../model/bookcase/IKEA_EXPEDIT_1/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 739/1024 samples!\n",
      "only got 824/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1645.jpg with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1382.jpg with mesh: ../model/table/IKEA_NORDEN_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0843.jpg with mesh: ../model/bed/IKEA_MANDAL_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 851/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 3: 0.07043041288852692\n",
      "Batch index 4 size: 16\n",
      "Processing image: ../resized_images/sofa/1917.jpg with mesh: ../model/sofa/IKEA_TIDAFORS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0938.jpg with mesh: ../model/bed/IKEA_TROMSO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1477.jpg with mesh: ../model/sofa/IKEA_SATER/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3409.jpg with mesh: ../model/chair/IKEA_STEFAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 764/1024 samples!\n",
      "only got 828/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/table/1077.jpg with mesh: ../model/table/IKEA_LACK_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2947.jpg with mesh: ../model/chair/IKEA_POANG_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0196.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3285.jpg with mesh: ../model/chair/IKEA_SNILLE_1/model_1.2589784775_0.00047638065865_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 676/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1026\n",
      "Processing image: ../resized_images/bed/0142.jpg with mesh: ../model/bed/IKEA_BRIMNES_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3292.jpg with mesh: ../model/chair/IKEA_SNILLE_1/model_0.798438221596_0.00881185769084_simple_normal.obj\n",
      "Vertices shape before padding: 1029\n",
      "Processing image: ../resized_images/bed/0002.png with mesh: ../model/bed/IKEA_MALM_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3675.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0257.jpg with mesh: ../model/desk/IKEA_LAIVA/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 969/1024 samples!\n",
      "only got 777/1024 samples!\n",
      "only got 936/1024 samples!\n",
      "only got 750/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3218.jpg with mesh: ../model/chair/IKEA_SIGURD/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0716.jpg with mesh: ../model/sofa/IKEA_KIVIK_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/0034.png with mesh: ../model/chair/IKEA_POANG_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 741/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 4: 0.061185650527477264\n",
      "Batch index 5 size: 16\n",
      "Processing image: ../resized_images/table/1432.jpg with mesh: ../model/table/IKEA_NORDEN_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2864.jpg with mesh: ../model/chair/IKEA_POANG_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 617/1024 samples!\n",
      "only got 709/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/table/1082.jpg with mesh: ../model/table/IKEA_LIATORP_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/wardrobe/0012.jpg with mesh: ../model/wardrobe/IKEA_ANEBODA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0938.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 326/1024 samples!\n",
      "only got 809/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/table/1540.jpg with mesh: ../model/table/IKEA_TOFTERYD/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1299.jpg with mesh: ../model/table/IKEA_NESNA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3359.jpg with mesh: ../model/chair/IKEA_SOLSTA_OLARP/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1698.jpg with mesh: ../model/sofa/IKEA_SOLSTA_d053e745b565fa391c1b3b2ed8d13bf8/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 1020/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/2225.jpg with mesh: ../model/chair/IKEA_JULES_1/model_-0.0710854941238_0.0242434357163_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0078.png with mesh: ../model/sofa/IKEA_KLIPPAN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0236.jpg with mesh: ../model/desk/IKEA_HEMNES/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0653.jpg with mesh: ../model/sofa/IKEA_KARLSTAD_3/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 979/1024 samples!\n",
      "only got 939/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1225.jpg with mesh: ../model/table/IKEA_MUDDUS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0694.jpg with mesh: ../model/sofa/IKEA_KIVIK_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/wardrobe/0207.jpg with mesh: ../model/wardrobe/IKEA_HEMNES/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 633/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 5: 0.05830979347229004\n",
      "Batch index 6 size: 16\n",
      "Processing image: ../resized_images/bed/0821.jpg with mesh: ../model/bed/IKEA_MALM_4/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0224.jpg with mesh: ../model/bookcase/IKEA_KILBY_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1109.jpg with mesh: ../model/table/IKEA_LINDVED/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 970/1024 samples!\n",
      "only got 738/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/wardrobe/0096.jpg with mesh: ../model/wardrobe/IKEA_ANEBODA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1170.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 943/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/sofa/1860.jpg with mesh: ../model/sofa/IKEA_TIDAFORS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1102.jpg with mesh: ../model/table/IKEA_LINDVED/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3699.jpg with mesh: ../model/chair/IKEA_URBAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0745.jpg with mesh: ../model/bed/IKEA_MALM_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 836/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/desk/0480.png with mesh: ../model/desk/IKEA_MALM/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/0048.png with mesh: ../model/chair/IKEA_INGOLF/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3514.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3730.jpg with mesh: ../model/chair/IKEA_VILMAR_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 634/1024 samples!\n",
      "only got 785/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/bookcase/0041.jpg with mesh: ../model/bookcase/IKEA_BILLY_4/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1763.jpg with mesh: ../model/sofa/IKEA_SOLSTA_d053e745b565fa391c1b3b2ed8d13bf8/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1032.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 757/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 6: 0.06411731243133545\n",
      "Batch index 7 size: 16\n",
      "Processing image: ../resized_images/table/1592.jpg with mesh: ../model/table/IKEA_TORSBY_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0687.jpg with mesh: ../model/desk/IKEA_GALANT_6/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0068.png with mesh: ../model/sofa/IKEA_KARLSTAD_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0784.jpg with mesh: ../model/table/IKEA_INGO_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0516.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3808.jpg with mesh: ../model/chair/IKEA_VILMAR_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0267.jpg with mesh: ../model/bed/IKEA_FJELLSE_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 1012/1024 samples!\n",
      "only got 753/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/2761.jpg with mesh: ../model/chair/IKEA_PATRIK/model_-0.195227319969_-0.0914830227742_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1715.jpg with mesh: ../model/sofa/IKEA_SOLSTA_d053e745b565fa391c1b3b2ed8d13bf8/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 883/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/desk/0084.jpg with mesh: ../model/desk/IKEA_BESTA_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0624.jpg with mesh: ../model/sofa/IKEA_KARLSTAD_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 667/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/2263.jpg with mesh: ../model/chair/IKEA_JULES_1/model_0.12490569255_0.125583418801_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1094.jpg with mesh: ../model/table/IKEA_LIATORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3228.jpg with mesh: ../model/chair/IKEA_SKRUVSTA/model_1.12407803524_0.372276788998_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1912.jpg with mesh: ../model/sofa/IKEA_TIDAFORS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0486.jpg with mesh: ../model/desk/IKEA_MICKE_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 804/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 7: 0.059964537620544434\n",
      "Batch index 8 size: 16\n",
      "Processing image: ../resized_images/chair/2315.jpg with mesh: ../model/chair/IKEA_JULES_1/model_-0.80735830594_0.0354079252926_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0080.png with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 754/1024 samples!\n",
      "only got 812/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/table/0897.jpg with mesh: ../model/table/IKEA_JOKKMOKK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2778.jpg with mesh: ../model/chair/IKEA_PATRIK/model_-0.0295468032558_-0.129092331388_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0295.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 794/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/2794.jpg with mesh: ../model/chair/IKEA_POANG_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1089\n",
      "Processing image: ../resized_images/sofa/1793.jpg with mesh: ../model/sofa/IKEA_SOLSTA_d053e745b565fa391c1b3b2ed8d13bf8/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 697/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/wardrobe/0004.jpg with mesh: ../model/wardrobe/IKEA_ANEBODA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 327/1024 samples!\n",
      "only got 849/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/3379.jpg with mesh: ../model/chair/IKEA_SOLSTA_OLARP/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3423.jpg with mesh: ../model/chair/IKEA_STEFAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2797.jpg with mesh: ../model/chair/IKEA_POANG_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1089\n",
      "Processing image: ../resized_images/bed/0458.jpg with mesh: ../model/bed/IKEA_HEMNES_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 699/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/bookcase/0152.jpg with mesh: ../model/bookcase/IKEA_EXPEDIT_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1370.jpg with mesh: ../model/table/IKEA_NORBO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2371.jpg with mesh: ../model/chair/IKEA_KAUSTBY/model_simple_normal.obj\n",
      "Vertices shape before padding: 1029\n",
      "Processing image: ../resized_images/table/0938.jpg with mesh: ../model/table/IKEA_KLINGSBO_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 949/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 8: 148022.875\n",
      "Batch index 9 size: 16\n",
      "Processing image: ../resized_images/chair/2235.jpg with mesh: ../model/chair/IKEA_JULES_1/model_-0.451099814687_-0.0265291315038_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2040.jpg with mesh: ../model/chair/IKEA_IVAR/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0623.png with mesh: ../model/sofa/IKEA_KARLSTAD_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0134.jpg with mesh: ../model/table/IKEA_BJORKUDDEN_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0685.jpg with mesh: ../model/sofa/IKEA_KIVIK_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 840/1024 samples!\n",
      "only got 717/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/sofa/0217.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/wardrobe/0097.jpg with mesh: ../model/wardrobe/IKEA_ANEBODA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0030.png with mesh: ../model/bed/IKEA_LILLESAND/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 881/1024 samples!\n",
      "only got 972/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/desk/0076.jpg with mesh: ../model/desk/IKEA_BESTA_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1227.jpg with mesh: ../model/table/IKEA_MUDDUS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0044.jpg with mesh: ../model/bed/IKEA_BEDDINGE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0179.jpg with mesh: ../model/bed/IKEA_BRIMNES_1/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 688/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2739.jpg with mesh: ../model/chair/IKEA_NILS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/0094.png with mesh: ../model/chair/IKEA_URBAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0554.jpg with mesh: ../model/desk/IKEA_MICKE_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1374.jpg with mesh: ../model/table/IKEA_NORBO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 9\n",
      "Loss at batch 9: 0.05968733876943588\n",
      "Batch index 10 size: 16\n",
      "Processing image: ../resized_images/table/0512.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3820.jpg with mesh: ../model/chair/IKEA_VILMAR_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0411.jpg with mesh: ../model/sofa/IKEA_KARLSTAD_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0179.jpg with mesh: ../model/desk/IKEA_GALANT_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3264.jpg with mesh: ../model/chair/IKEA_SNILLE_1/model_-0.281731131582_-0.00245505700317_simple_normal.obj\n",
      "Vertices shape before padding: 1025\n",
      "Processing image: ../resized_images/desk/0362.jpg with mesh: ../model/desk/IKEA_LIATORP/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1754.jpg with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0443.jpg with mesh: ../model/desk/IKEA_MALM/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3545.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1220.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0074.jpg with mesh: ../model/desk/IKEA_BESTA_2/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 862/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1845.jpg with mesh: ../model/sofa/IKEA_TIDAFORS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1391.jpg with mesh: ../model/sofa/IKEA_MANSTAD/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 810/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1715.jpg with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0382.jpg with mesh: ../model/table/IKEA_DOCKSTA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1481.jpg with mesh: ../model/table/IKEA_RAST/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 549/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 10: 0.06397464126348495\n",
      "Batch index 11 size: 16\n",
      "Processing image: ../resized_images/bookcase/0044.jpg with mesh: ../model/bookcase/IKEA_BILLY_5/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1678.jpg with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 843/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/3389.jpg with mesh: ../model/chair/IKEA_STEFAN/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1472.jpg with mesh: ../model/sofa/IKEA_SATER/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2283.jpg with mesh: ../model/chair/IKEA_JULES_1/model_-0.0657745456674_-0.0312234888432_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 805/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/3250.jpg with mesh: ../model/chair/IKEA_SNILLE_1/model_0.520530650066_0.0762078650951_simple_normal.obj\n",
      "Vertices shape before padding: 1028\n",
      "Processing image: ../resized_images/table/0634.jpg with mesh: ../model/table/IKEA_HEMNES_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/1745.png with mesh: ../model/chair/IKEA_BORJE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 562/1024 samples!\n",
      "only got 818/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/wardrobe/0116.jpg with mesh: ../model/wardrobe/IKEA_DOMBAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0288.jpg with mesh: ../model/sofa/IKEA_EKTORP_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1197.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0244.jpg with mesh: ../model/bed/IKEA_FJELLSE_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 687/1024 samples!\n",
      "only got 655/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/wardrobe/0032.jpg with mesh: ../model/wardrobe/IKEA_ANEBODA_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0321.jpg with mesh: ../model/bookcase/IKEA_LAIVA/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1189.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1351.jpg with mesh: ../model/table/IKEA_NORBO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 817/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at batch 11: 0.048741456121206284\n",
      "Batch index 12 size: 16\n",
      "Processing image: ../resized_images/sofa/0366.jpg with mesh: ../model/sofa/IKEA_EKTORP_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3146.jpg with mesh: ../model/chair/IKEA_REIDAR/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 960/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/sofa/0822.jpg with mesh: ../model/sofa/IKEA_KIVIK_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 1017/1024 samples!\n",
      "only got 715/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/desk/0225.jpg with mesh: ../model/desk/IKEA_HEMNES/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/1642.jpeg with mesh: ../model/table/IKEA_TORSBY_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0969.jpg with mesh: ../model/bed/IKEA_TROMSO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3360.jpg with mesh: ../model/chair/IKEA_SOLSTA_OLARP/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 312/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/desk/0198.jpg with mesh: ../model/desk/IKEA_GALANT_5/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2087.jpg with mesh: ../model/chair/IKEA_IVAR/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0169.jpg with mesh: ../model/bookcase/IKEA_HEMNES/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1866.jpg with mesh: ../model/sofa/IKEA_TIDAFORS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1530.jpg with mesh: ../model/sofa/IKEA_SATER/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 815/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/chair/2710.jpg with mesh: ../model/chair/IKEA_NILS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0686.jpg with mesh: ../model/table/IKEA_HEMNES_4/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0377.jpg with mesh: ../model/sofa/IKEA_EKTORP_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0351.jpg with mesh: ../model/bed/IKEA_HEMNES_2/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 971/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 12\n",
      "Loss at batch 12: 0.05632799491286278\n",
      "Batch index 13 size: 16\n",
      "Processing image: ../resized_images/chair/2592.jpg with mesh: ../model/chair/IKEA_MARIUS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/0018.png with mesh: ../model/chair/IKEA_POANG_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1089\n",
      "Processing image: ../resized_images/bed/0192.jpg with mesh: ../model/bed/IKEA_BRIMNES_2/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1128.jpg with mesh: ../model/sofa/IKEA_KLIPPAN_2/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 623/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0584.jpg with mesh: ../model/bed/IKEA_LEIRVIK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0579.jpg with mesh: ../model/sofa/IKEA_KARLSTAD_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/2269.jpg with mesh: ../model/chair/IKEA_JULES_1/model_-0.443464595833_0.108495861806_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 609/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0545.jpeg with mesh: ../model/bed/IKEA_LEIRVIK/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0964.jpg with mesh: ../model/bed/IKEA_TROMSO/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/table/0545.jpg with mesh: ../model/table/IKEA_FUSION/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/chair/3569.jpg with mesh: ../model/chair/IKEA_TOBIAS/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bookcase/0122.jpg with mesh: ../model/bookcase/IKEA_EXPEDIT_3/model_simple_normal.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 703/1024 samples!\n",
      "only got 794/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/1647.jpg with mesh: ../model/sofa/IKEA_SOLSTA_d053e745b565fa391c1b3b2ed8d13bf8/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 812/1024 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ../resized_images/bed/0054.jpg with mesh: ../model/bed/IKEA_BEDDINGE/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/bed/0242.jpg with mesh: ../model/bed/IKEA_FJELLSE_1/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing image: ../resized_images/sofa/0378.jpg with mesh: ../model/sofa/IKEA_EKTORP_3/model_simple_normal.obj\n",
      "Vertices shape before padding: 1024\n",
      "Processing batch index: 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mfor\u001b[39;00m index, (inputs, targets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data_gen):\n\u001b[1;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing batch index: \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(inputs, targets, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss at batch \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     52\u001b[0m     train_data_gen,\n\u001b[1;32m     53\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m     54\u001b[0m     validation_data\u001b[39m=\u001b[39mval_data_gen\n\u001b[1;32m     55\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:433\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    432\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 433\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_function(iterator)\n\u001b[1;32m    434\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    435\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "img_dir = \"../resized_images/\"\n",
    "img_paths = []\n",
    "\n",
    "# Iterate over the images in the directory, but only add those present in the JSON mapping\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(root, file)\n",
    "\n",
    "            # Check if the image path is in the mapping\n",
    "            if img_path in img_to_mod_map:\n",
    "                img_paths.append(img_path)\n",
    "\n",
    "print(f\"Found {len(img_paths)} images.\")\n",
    "\n",
    "train_img_paths, temp_img_paths = train_test_split(img_paths, test_size=0.3, random_state=42)\n",
    "val_img_paths, test_img_paths = train_test_split(temp_img_paths, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data_gen = DataGenerator(train_img_paths, img_to_mod_map, material_properties, batch_size=16, augment=True)\n",
    "val_data_gen = DataGenerator(val_img_paths, img_to_mod_map, material_properties, batch_size=16, augment=False)\n",
    "test_data_gen = DataGenerator(test_img_paths, img_to_mod_map, material_properties, batch_size=16, augment=False)\n",
    "\n",
    "def generator_to_tf_dataset(generator):\n",
    "    output_signature = (\n",
    "        (\n",
    "            tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 12), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None, 1024, 3), dtype=tf.float32)\n",
    "    )\n",
    "    return tf.data.Dataset.from_generator(lambda: generator, output_signature=output_signature)\n",
    "\n",
    "train_dataset = generator_to_tf_dataset(train_data_gen)\n",
    "val_dataset = generator_to_tf_dataset(val_data_gen)\n",
    "test_dataset = generator_to_tf_dataset(test_data_gen)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# for i in range(len(train_data_gen)):\n",
    "#     print(f\"Iteration: {i}\")\n",
    "#     data = train_data_gen[i]\n",
    "#     print(f\"Batch {i} processed\")\n",
    "\n",
    "for index, (inputs, targets) in enumerate(train_data_gen):\n",
    "    print(f\"Processing batch index: {index}\")\n",
    "    loss = model.evaluate(inputs, targets, verbose=0)\n",
    "    print(f\"Loss at batch {index}: {loss}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=20,\n",
    "    validation_data=val_data_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mayplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8110e51c1d4d631a5b9d1ce506b9869acf625cbf303a36efadedb1aaf848f0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
